#!/usr/bin/env python3
"""
Ğ¢ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ğ¾Ğ»Ğ½Ğ¾Ğ¹ Ğ¸Ğ½Ñ„Ñ€Ğ°ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñ‹ JONQUILS Music Service
ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµÑ‚ Ğ²ÑĞµ ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ñ‹: PostgreSQL, ClickHouse, Elasticsearch, MinIO, Redis
"""

import asyncio
import boto3
import json
import logging
import os
import sys
import time
from datetime import datetime
from io import BytesIO
from pathlib import Path

import asyncpg
import httpx
import redis
from clickhouse_driver import Client
from elasticsearch import Elasticsearch

# ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class InfrastructureTest:
    def __init__(self):
        """Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ñ‚ĞµÑÑ‚Ğ¾Ğ² Ğ¸Ğ½Ñ„Ñ€Ğ°ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñ‹"""
        self.results = {
            'tests_run': 0,
            'tests_passed': 0,
            'tests_failed': 0,
            'details': {}
        }
        
        # ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ
        self.config = {
            'postgres': {
                'host': 'localhost',
                'port': 5432,
                'user': 'erik',
                'password': '2004',
                'database': 'music_service_db'
            },
            'clickhouse': {
                'host': 'localhost',
                'port': 9000,
                'user': 'admin',
                'password': 'admin123',
                'database': 'jonquils_analytics'
            },
            'elasticsearch': {
                'host': 'localhost',
                'port': 9200
            },
            'redis': {
                'host': 'localhost',
                'port': 6379,
                'password': 'redispass123'
            },
            'minio': {
                'endpoint': 'http://localhost:9002',
                'access_key': 'minioadmin',
                'secret_key': 'minioadmin123'
            },
            'api': {
                'base_url': 'http://localhost:8000'
            }
        }

    def test_result(self, test_name: str, success: bool, details: str = ""):
        """Ğ—Ğ°Ğ¿Ğ¸ÑÑ‹Ğ²Ğ°ĞµÑ‚ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ Ñ‚ĞµÑÑ‚Ğ°"""
        self.results['tests_run'] += 1
        if success:
            self.results['tests_passed'] += 1
            logger.info(f"âœ… {test_name}: PASSED")
        else:
            self.results['tests_failed'] += 1
            logger.error(f"âŒ {test_name}: FAILED - {details}")
        
        self.results['details'][test_name] = {
            'passed': success,
            'details': details,
            'timestamp': datetime.now().isoformat()
        }

    async def test_postgresql(self):
        """Ğ¢ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ PostgreSQL"""
        logger.info("ğŸ” Testing PostgreSQL...")
        
        try:
            # ĞŸĞ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ Ğº PostgreSQL
            conn = await asyncpg.connect(
                host=self.config['postgres']['host'],
                port=self.config['postgres']['port'],
                user=self.config['postgres']['user'],
                password=self.config['postgres']['password'],
                database=self.config['postgres']['database']
            )
            
            # Ğ¢ĞµÑÑ‚ Ğ±Ğ°Ğ·Ğ¾Ğ²Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ñ
            result = await conn.fetchval("SELECT 1")
            self.test_result("PostgreSQL Connection", result == 1)
            
            # Ğ¢ĞµÑÑ‚ ÑÑ…ĞµĞ¼ ETL
            schemas = await conn.fetch("""
                SELECT schema_name FROM information_schema.schemata 
                WHERE schema_name IN ('etl', 'staging', 'data_warehouse')
            """)
            schema_names = [row['schema_name'] for row in schemas]
            self.test_result("PostgreSQL ETL Schemas", 
                           all(s in schema_names for s in ['etl', 'staging', 'data_warehouse']))
            
            # Ğ¢ĞµÑÑ‚ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†
            tables = await conn.fetch("""
                SELECT table_name FROM information_schema.tables 
                WHERE table_schema = 'etl' AND table_name = 'etl_jobs'
            """)
            self.test_result("PostgreSQL ETL Tables", len(tables) > 0)
            
            await conn.close()
            
        except Exception as e:
            self.test_result("PostgreSQL Connection", False, str(e))

    def test_clickhouse(self):
        """Ğ¢ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ ClickHouse"""
        logger.info("ğŸ” Testing ClickHouse...")
        
        try:
            # ĞŸĞ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ Ğº ClickHouse
            client = Client(
                host=self.config['clickhouse']['host'],
                port=self.config['clickhouse']['port'],
                user=self.config['clickhouse']['user'],
                password=self.config['clickhouse']['password'],
                database=self.config['clickhouse']['database']
            )
            
            # Ğ¢ĞµÑÑ‚ Ğ±Ğ°Ğ·Ğ¾Ğ²Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ñ
            result = client.execute("SELECT 1")[0][0]
            self.test_result("ClickHouse Connection", result == 1)
            
            # Ğ¢ĞµÑÑ‚ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ† Ğ°Ğ½Ğ°Ğ»Ğ¸Ñ‚Ğ¸ĞºĞ¸
            tables = client.execute("SHOW TABLES")
            table_names = [table[0] for table in tables]
            required_tables = ['track_analytics', 'user_analytics', 'search_analytics']
            
            self.test_result("ClickHouse Analytics Tables", 
                           all(table in table_names for table in required_tables))
            
            # Ğ¢ĞµÑÑ‚ Ğ²ÑÑ‚Ğ°Ğ²ĞºĞ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
            test_data = [(
                datetime.now(),
                1,
                'test_track_1',
                'play',
                180,
                'high',
                'web',
                '{"test": true}'
            )]
            
            client.execute("""
                INSERT INTO track_analytics 
                (timestamp, user_id, track_id, event_type, duration, quality, platform, metadata)
                VALUES
            """, test_data)
            
            # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ²ÑÑ‚Ğ°Ğ²ĞºÑƒ
            count = client.execute("""
                SELECT COUNT(*) FROM track_analytics 
                WHERE track_id = 'test_track_1'
            """)[0][0]
            
            self.test_result("ClickHouse Data Insert", count > 0)
            
            # ĞÑ‡Ğ¸Ñ‰Ğ°ĞµĞ¼ Ñ‚ĞµÑÑ‚Ğ¾Ğ²Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ
            client.execute("DELETE FROM track_analytics WHERE track_id = 'test_track_1'")
            
        except Exception as e:
            self.test_result("ClickHouse Connection", False, str(e))

    def test_elasticsearch(self):
        """Ğ¢ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Elasticsearch"""
        logger.info("ğŸ” Testing Elasticsearch...")
        
        try:
            # ĞŸĞ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ Ğº Elasticsearch
            es = Elasticsearch([
                f"http://{self.config['elasticsearch']['host']}:{self.config['elasticsearch']['port']}"
            ])
            
            # Ğ¢ĞµÑÑ‚ Ğ±Ğ°Ğ·Ğ¾Ğ²Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ñ
            health = es.cluster.health()
            self.test_result("Elasticsearch Connection", health['status'] in ['green', 'yellow'])
            
            # Ğ¢ĞµÑÑ‚ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ Ğ¸Ğ½Ğ´ĞµĞºÑĞ°
            index_name = 'test_tracks'
            if es.indices.exists(index=index_name):
                es.indices.delete(index=index_name)
            
            es.indices.create(index=index_name, body={
                'mappings': {
                    'properties': {
                        'title': {'type': 'text'},
                        'artist': {'type': 'text'},
                        'duration': {'type': 'integer'}
                    }
                }
            })
            
            self.test_result("Elasticsearch Index Creation", True)
            
            # Ğ¢ĞµÑÑ‚ Ğ¸Ğ½Ğ´ĞµĞºÑĞ°Ñ†Ğ¸Ğ¸ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°
            test_doc = {
                'title': 'Test Track',
                'artist': 'Test Artist',
                'duration': 180
            }
            
            response = es.index(index=index_name, document=test_doc)
            self.test_result("Elasticsearch Document Index", response['result'] == 'created')
            
            # Ğ–Ğ´ĞµĞ¼ Ğ¸Ğ½Ğ´ĞµĞºÑĞ°Ñ†Ğ¸Ğ¸
            time.sleep(1)
            es.indices.refresh(index=index_name)
            
            # Ğ¢ĞµÑÑ‚ Ğ¿Ğ¾Ğ¸ÑĞºĞ°
            search_result = es.search(index=index_name, body={
                'query': {'match': {'title': 'Test Track'}}
            })
            
            self.test_result("Elasticsearch Search", 
                           search_result['hits']['total']['value'] > 0)
            
            # Ğ£Ğ´Ğ°Ğ»ÑĞµĞ¼ Ñ‚ĞµÑÑ‚Ğ¾Ğ²Ñ‹Ğ¹ Ğ¸Ğ½Ğ´ĞµĞºÑ
            es.indices.delete(index=index_name)
            
        except Exception as e:
            self.test_result("Elasticsearch Connection", False, str(e))

    def test_redis(self):
        """Ğ¢ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Redis"""
        logger.info("ğŸ” Testing Redis...")
        
        try:
            # ĞŸĞ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ Ğº Redis
            r = redis.Redis(
                host=self.config['redis']['host'],
                port=self.config['redis']['port'],
                password=self.config['redis']['password'],
                decode_responses=True
            )
            
            # Ğ¢ĞµÑÑ‚ Ğ±Ğ°Ğ·Ğ¾Ğ²Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ñ
            pong = r.ping()
            self.test_result("Redis Connection", pong)
            
            # Ğ¢ĞµÑÑ‚ Ğ·Ğ°Ğ¿Ğ¸ÑĞ¸/Ñ‡Ñ‚ĞµĞ½Ğ¸Ñ
            test_key = 'test_key'
            test_value = 'test_value'
            
            r.set(test_key, test_value, ex=60)  # TTL 60 ÑĞµĞºÑƒĞ½Ğ´
            retrieved_value = r.get(test_key)
            
            self.test_result("Redis Set/Get", retrieved_value == test_value)
            
            # Ğ¢ĞµÑÑ‚ ÑĞ¿Ğ¸ÑĞºĞ¾Ğ² (Ğ´Ğ»Ñ Ğ¾Ñ‡ĞµÑ€ĞµĞ´ĞµĞ¹)
            queue_name = 'test_queue'
            r.lpush(queue_name, 'task1', 'task2', 'task3')
            queue_length = r.llen(queue_name)
            
            self.test_result("Redis Queue Operations", queue_length == 3)
            
            # ĞÑ‡Ğ¸ÑÑ‚ĞºĞ° Ñ‚ĞµÑÑ‚Ğ¾Ğ²Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
            r.delete(test_key, queue_name)
            
        except Exception as e:
            self.test_result("Redis Connection", False, str(e))

    def test_minio(self):
        """Ğ¢ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ MinIO (S3)"""
        logger.info("ğŸ” Testing MinIO...")
        
        try:
            # ĞŸĞ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ Ğº MinIO
            s3_client = boto3.client(
                's3',
                endpoint_url=self.config['minio']['endpoint'],
                aws_access_key_id=self.config['minio']['access_key'],
                aws_secret_access_key=self.config['minio']['secret_key']
            )
            
            # Ğ¢ĞµÑÑ‚ ÑĞ¿Ğ¸ÑĞºĞ° buckets
            buckets = s3_client.list_buckets()
            bucket_names = [bucket['Name'] for bucket in buckets['Buckets']]
            required_buckets = ['tracks', 'covers', 'playlists', 'temp']
            
            self.test_result("MinIO Buckets", 
                           all(bucket in bucket_names for bucket in required_buckets))
            
            # Ğ¢ĞµÑÑ‚ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸ Ñ„Ğ°Ğ¹Ğ»Ğ°
            test_content = b"This is a test file for MinIO"
            test_key = f"test/test_file_{int(time.time())}.txt"
            
            s3_client.put_object(
                Bucket='temp',
                Key=test_key,
                Body=test_content,
                ContentType='text/plain'
            )
            
            self.test_result("MinIO Upload", True)
            
            # Ğ¢ĞµÑÑ‚ ÑĞºĞ°Ñ‡Ğ¸Ğ²Ğ°Ğ½Ğ¸Ñ Ñ„Ğ°Ğ¹Ğ»Ğ°
            response = s3_client.get_object(Bucket='temp', Key=test_key)
            downloaded_content = response['Body'].read()
            
            self.test_result("MinIO Download", downloaded_content == test_content)
            
            # Ğ¢ĞµÑÑ‚ Ğ¼ĞµÑ‚Ğ°Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
            head_response = s3_client.head_object(Bucket='temp', Key=test_key)
            self.test_result("MinIO Metadata", 'ContentLength' in head_response)
            
            # Ğ£Ğ´Ğ°Ğ»ÑĞµĞ¼ Ñ‚ĞµÑÑ‚Ğ¾Ğ²Ñ‹Ğ¹ Ñ„Ğ°Ğ¹Ğ»
            s3_client.delete_object(Bucket='temp', Key=test_key)
            
        except Exception as e:
            self.test_result("MinIO Connection", False, str(e))

    async def test_fastapi(self):
        """Ğ¢ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ FastAPI"""
        logger.info("ğŸ” Testing FastAPI...")
        
        try:
            async with httpx.AsyncClient() as client:
                # Ğ¢ĞµÑÑ‚ health endpoint
                response = await client.get(f"{self.config['api']['base_url']}/health")
                if response.status_code == 404:
                    # Ğ•ÑĞ»Ğ¸ Ğ½ĞµÑ‚ health endpoint, Ñ‚ĞµÑÑ‚Ğ¸Ñ€ÑƒĞµĞ¼ docs
                    response = await client.get(f"{self.config['api']['base_url']}/docs")
                
                self.test_result("FastAPI Health", response.status_code in [200, 307])
                
                # Ğ¢ĞµÑÑ‚ OpenAPI docs
                docs_response = await client.get(f"{self.config['api']['base_url']}/docs")
                self.test_result("FastAPI OpenAPI Docs", docs_response.status_code in [200, 307])
                
        except Exception as e:
            self.test_result("FastAPI Connection", False, str(e))

    def test_docker_services(self):
        """Ğ¢ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Docker ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€Ğ¾Ğ²"""
        logger.info("ğŸ” Testing Docker Services...")
        
        try:
            import subprocess
            
            # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ·Ğ°Ğ¿ÑƒÑ‰ĞµĞ½Ğ½Ñ‹Ğµ ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€Ñ‹
            result = subprocess.run(
                ['docker', 'ps', '--format', 'table {{.Names}}\t{{.Status}}'],
                capture_output=True,
                text=True
            )
            
            if result.returncode == 0:
                containers = result.stdout
                required_containers = [
                    'jonquils-postgres',
                    'jonquils-clickhouse', 
                    'jonquils-elasticsearch',
                    'jonquils-redis',
                    'jonquils-minio'
                ]
                
                running_containers = []
                for container in required_containers:
                    if container in containers and 'Up' in containers:
                        running_containers.append(container)
                
                self.test_result("Docker Containers", 
                               len(running_containers) == len(required_containers),
                               f"Running: {running_containers}")
            else:
                self.test_result("Docker Containers", False, "Docker not available")
                
        except Exception as e:
            self.test_result("Docker Containers", False, str(e))

    async def run_all_tests(self):
        """Ğ—Ğ°Ğ¿ÑƒÑĞº Ğ²ÑĞµÑ… Ñ‚ĞµÑÑ‚Ğ¾Ğ²"""
        logger.info("ğŸš€ Starting Infrastructure Tests...")
        start_time = time.time()
        
        # Ğ—Ğ°Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ Ğ²ÑĞµ Ñ‚ĞµÑÑ‚Ñ‹
        await self.test_postgresql()
        self.test_clickhouse()
        self.test_elasticsearch()
        self.test_redis()
        self.test_minio()
        await self.test_fastapi()
        self.test_docker_services()
        
        end_time = time.time()
        
        # Ğ’Ñ‹Ğ²Ğ¾Ğ´Ğ¸Ğ¼ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹
        logger.info("=" * 60)
        logger.info("ğŸ“Š TEST RESULTS SUMMARY")
        logger.info("=" * 60)
        logger.info(f"Tests Run: {self.results['tests_run']}")
        logger.info(f"Tests Passed: {self.results['tests_passed']}")
        logger.info(f"Tests Failed: {self.results['tests_failed']}")
        logger.info(f"Success Rate: {(self.results['tests_passed']/self.results['tests_run']*100):.1f}%")
        logger.info(f"Execution Time: {end_time - start_time:.2f} seconds")
        
        if self.results['tests_failed'] > 0:
            logger.info("\nâŒ FAILED TESTS:")
            for test_name, details in self.results['details'].items():
                if not details['passed']:
                    logger.info(f"  - {test_name}: {details['details']}")
        
        # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ² Ñ„Ğ°Ğ¹Ğ»
        with open('test_results.json', 'w') as f:
            json.dump(self.results, f, indent=2)
        
        logger.info(f"\nğŸ“„ Detailed results saved to: test_results.json")
        
        return self.results['tests_failed'] == 0

async def main():
    """Ğ“Ğ»Ğ°Ğ²Ğ½Ğ°Ñ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ"""
    tester = InfrastructureTest()
    success = await tester.run_all_tests()
    
    if success:
        logger.info("ğŸ‰ All tests passed! Infrastructure is ready.")
        sys.exit(0)
    else:
        logger.error("ğŸ’¥ Some tests failed. Please check the issues above.")
        sys.exit(1)

if __name__ == "__main__":
    asyncio.run(main())
