#!/usr/bin/env python3
"""
–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–ª–Ω–æ–π –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä—ã JONQUILS Music Service
–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –≤—Å–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã: PostgreSQL, ClickHouse, Elasticsearch, MinIO, Redis
"""

import asyncio
import boto3
import json
import logging
import os
import sys
import time
from datetime import datetime
from io import BytesIO
from pathlib import Path

import asyncpg
import httpx
import redis
from clickhouse_driver import Client
from elasticsearch import Elasticsearch

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class InfrastructureTest:
    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ç–µ—Å—Ç–æ–≤ –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä—ã"""
        self.results = {
            'tests_run': 0,
            'tests_passed': 0,
            'tests_failed': 0,
            'details': {}
        }
        
        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
        self.config = {
            'postgres': {
                'host': 'localhost',
                'port': 5432,
                'user': 'erik',
                'password': '2004',
                'database': 'music_service_db'
            },
            'clickhouse': {
                'host': 'localhost',
                'port': 9000,
                'user': 'admin',
                'password': 'admin123',
                'database': 'jonquils_analytics'
            },
            'elasticsearch': {
                'host': 'localhost',
                'port': 9200
            },
            'redis': {
                'host': 'localhost',
                'port': 6379,
                'password': 'redispass123'
            },
            'minio': {
                'endpoint': 'http://localhost:9002',
                'access_key': 'minioadmin',
                'secret_key': 'minioadmin123'
            },
            'api': {
                'base_url': 'http://localhost:8000'
            }
        }

    def test_result(self, test_name: str, success: bool, details: str = ""):
        """–ó–∞–ø–∏—Å—ã–≤–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ç–µ—Å—Ç–∞"""
        self.results['tests_run'] += 1
        if success:
            self.results['tests_passed'] += 1
            logger.info(f"‚úÖ {test_name}: PASSED")
        else:
            self.results['tests_failed'] += 1
            logger.error(f"‚ùå {test_name}: FAILED - {details}")
        
        self.results['details'][test_name] = {
            'passed': success,
            'details': details,
            'timestamp': datetime.now().isoformat()
        }

    async def test_postgresql(self):
        """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ PostgreSQL"""
        logger.info("üîç Testing PostgreSQL...")
        
        try:
            # –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ PostgreSQL
            conn = await asyncpg.connect(
                host=self.config['postgres']['host'],
                port=self.config['postgres']['port'],
                user=self.config['postgres']['user'],
                password=self.config['postgres']['password'],
                database=self.config['postgres']['database']
            )
            
            # –¢–µ—Å—Ç –±–∞–∑–æ–≤–æ–≥–æ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è
            result = await conn.fetchval("SELECT 1")
            self.test_result("PostgreSQL Connection", result == 1)
            
            # –¢–µ—Å—Ç —Å—Ö–µ–º ETL
            schemas = await conn.fetch("""
                SELECT schema_name FROM information_schema.schemata 
                WHERE schema_name IN ('etl', 'staging', 'data_warehouse')
            """)
            schema_names = [row['schema_name'] for row in schemas]
            self.test_result("PostgreSQL ETL Schemas", 
                           all(s in schema_names for s in ['etl', 'staging', 'data_warehouse']))
            
            # –¢–µ—Å—Ç —Ç–∞–±–ª–∏—Ü
            tables = await conn.fetch("""
                SELECT table_name FROM information_schema.tables 
                WHERE table_schema = 'etl' AND table_name = 'etl_jobs'
            """)
            self.test_result("PostgreSQL ETL Tables", len(tables) > 0)
            
            await conn.close()
            
        except Exception as e:
            self.test_result("PostgreSQL Connection", False, str(e))

    def test_clickhouse(self):
        """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ ClickHouse"""
        logger.info("üîç Testing ClickHouse...")
        
        try:
            # –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ ClickHouse
            client = Client(
                host=self.config['clickhouse']['host'],
                port=self.config['clickhouse']['port'],
                user=self.config['clickhouse']['user'],
                password=self.config['clickhouse']['password'],
                database=self.config['clickhouse']['database']
            )
            
            # –¢–µ—Å—Ç –±–∞–∑–æ–≤–æ–≥–æ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è
            result = client.execute("SELECT 1")[0][0]
            self.test_result("ClickHouse Connection", result == 1)
            
            # –¢–µ—Å—Ç —Ç–∞–±–ª–∏—Ü –∞–Ω–∞–ª–∏—Ç–∏–∫–∏
            tables = client.execute("SHOW TABLES")
            table_names = [table[0] for table in tables]
            required_tables = ['track_analytics', 'user_analytics', 'search_analytics']
            
            self.test_result("ClickHouse Analytics Tables", 
                           all(table in table_names for table in required_tables))
            
            # –¢–µ—Å—Ç –≤—Å—Ç–∞–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö
            test_data = [(
                datetime.now(),
                1,
                'test_track_1',
                'play',
                180,
                'high',
                'web',
                '{"test": true}'
            )]
            
            client.execute("""
                INSERT INTO track_analytics 
                (timestamp, user_id, track_id, event_type, duration, quality, platform, metadata)
                VALUES
            """, test_data)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Å—Ç–∞–≤–∫—É
            count = client.execute("""
                SELECT COUNT(*) FROM track_analytics 
                WHERE track_id = 'test_track_1'
            """)[0][0]
            
            self.test_result("ClickHouse Data Insert", count > 0)
            
            # –û—á–∏—â–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
            client.execute("DELETE FROM track_analytics WHERE track_id = 'test_track_1'")
            
        except Exception as e:
            self.test_result("ClickHouse Connection", False, str(e))

    def test_elasticsearch(self):
        """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ Elasticsearch"""
        logger.info("üîç Testing Elasticsearch...")
        
        try:
            # –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Elasticsearch
            es = Elasticsearch([
                f"http://{self.config['elasticsearch']['host']}:{self.config['elasticsearch']['port']}"
            ])
            
            # –¢–µ—Å—Ç –±–∞–∑–æ–≤–æ–≥–æ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è
            health = es.cluster.health()
            self.test_result("Elasticsearch Connection", health['status'] in ['green', 'yellow'])
            
            # –¢–µ—Å—Ç —Å–æ–∑–¥–∞–Ω–∏—è –∏–Ω–¥–µ–∫—Å–∞
            index_name = 'test_tracks'
            if es.indices.exists(index=index_name):
                es.indices.delete(index=index_name)
            
            es.indices.create(index=index_name, body={
                'mappings': {
                    'properties': {
                        'title': {'type': 'text'},
                        'artist': {'type': 'text'},
                        'duration': {'type': 'integer'}
                    }
                }
            })
            
            self.test_result("Elasticsearch Index Creation", True)
            
            # –¢–µ—Å—Ç –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞
            test_doc = {
                'title': 'Test Track',
                'artist': 'Test Artist',
                'duration': 180
            }
            
            response = es.index(index=index_name, document=test_doc)
            self.test_result("Elasticsearch Document Index", response['result'] == 'created')
            
            # –ñ–¥–µ–º –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏
            time.sleep(1)
            es.indices.refresh(index=index_name)
            
            # –¢–µ—Å—Ç –ø–æ–∏—Å–∫–∞
            search_result = es.search(index=index_name, body={
                'query': {'match': {'title': 'Test Track'}}
            })
            
            self.test_result("Elasticsearch Search", 
                           search_result['hits']['total']['value'] > 0)
            
            # –£–¥–∞–ª—è–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π –∏–Ω–¥–µ–∫—Å
            es.indices.delete(index=index_name)
            
        except Exception as e:
            self.test_result("Elasticsearch Connection", False, str(e))

    def test_redis(self):
        """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ Redis"""
        logger.info("üîç Testing Redis...")
        
        try:
            # –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Redis
            r = redis.Redis(
                host=self.config['redis']['host'],
                port=self.config['redis']['port'],
                password=self.config['redis']['password'],
                decode_responses=True
            )
            
            # –¢–µ—Å—Ç –±–∞–∑–æ–≤–æ–≥–æ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è
            pong = r.ping()
            self.test_result("Redis Connection", pong)
            
            # –¢–µ—Å—Ç –∑–∞–ø–∏—Å–∏/—á—Ç–µ–Ω–∏—è
            test_key = 'test_key'
            test_value = 'test_value'
            
            r.set(test_key, test_value, ex=60)  # TTL 60 —Å–µ–∫—É–Ω–¥
            retrieved_value = r.get(test_key)
            
            self.test_result("Redis Set/Get", retrieved_value == test_value)
            
            # –¢–µ—Å—Ç —Å–ø–∏—Å–∫–æ–≤ (–¥–ª—è –æ—á–µ—Ä–µ–¥–µ–π)
            queue_name = 'test_queue'
            r.lpush(queue_name, 'task1', 'task2', 'task3')
            queue_length = r.llen(queue_name)
            
            self.test_result("Redis Queue Operations", queue_length == 3)
            
            # –û—á–∏—Å—Ç–∫–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            r.delete(test_key, queue_name)
            
        except Exception as e:
            self.test_result("Redis Connection", False, str(e))

    def test_minio(self):
        """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ MinIO (S3)"""
        logger.info("üîç Testing MinIO...")
        
        try:
            # –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ MinIO
            s3_client = boto3.client(
                's3',
                endpoint_url=self.config['minio']['endpoint'],
                aws_access_key_id=self.config['minio']['access_key'],
                aws_secret_access_key=self.config['minio']['secret_key']
            )
            
            # –¢–µ—Å—Ç —Å–ø–∏—Å–∫–∞ buckets
            buckets = s3_client.list_buckets()
            bucket_names = [bucket['Name'] for bucket in buckets['Buckets']]
            required_buckets = ['tracks', 'covers', 'playlists', 'temp']
            
            self.test_result("MinIO Buckets", 
                           all(bucket in bucket_names for bucket in required_buckets))
            
            # –¢–µ—Å—Ç –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞
            test_content = b"This is a test file for MinIO"
            test_key = f"test/test_file_{int(time.time())}.txt"
            
            s3_client.put_object(
                Bucket='temp',
                Key=test_key,
                Body=test_content,
                ContentType='text/plain'
            )
            
            self.test_result("MinIO Upload", True)
            
            # –¢–µ—Å—Ç —Å–∫–∞—á–∏–≤–∞–Ω–∏—è —Ñ–∞–π–ª–∞
            response = s3_client.get_object(Bucket='temp', Key=test_key)
            downloaded_content = response['Body'].read()
            
            self.test_result("MinIO Download", downloaded_content == test_content)
            
            # –¢–µ—Å—Ç –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
            head_response = s3_client.head_object(Bucket='temp', Key=test_key)
            self.test_result("MinIO Metadata", 'ContentLength' in head_response)
            
            # –£–¥–∞–ª—è–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª
            s3_client.delete_object(Bucket='temp', Key=test_key)
            
        except Exception as e:
            self.test_result("MinIO Connection", False, str(e))

    async def test_fastapi(self):
        """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ FastAPI"""
        logger.info("üîç Testing FastAPI...")
        
        try:
            async with httpx.AsyncClient() as client:
                # –¢–µ—Å—Ç health endpoint
                response = await client.get(f"{self.config['api']['base_url']}/health")
                if response.status_code == 404:
                    # –ï—Å–ª–∏ –Ω–µ—Ç health endpoint, —Ç–µ—Å—Ç–∏—Ä—É–µ–º docs
                    response = await client.get(f"{self.config['api']['base_url']}/docs")
                
                self.test_result("FastAPI Health", response.status_code in [200, 307])
                
                # –¢–µ—Å—Ç OpenAPI docs
                docs_response = await client.get(f"{self.config['api']['base_url']}/docs")
                self.test_result("FastAPI OpenAPI Docs", docs_response.status_code in [200, 307])
                
        except Exception as e:
            self.test_result("FastAPI Connection", False, str(e))

    def test_docker_services(self):
        """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ Docker –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤"""
        logger.info("üîç Testing Docker Services...")
        
        try:
            import subprocess
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–∞–ø—É—â–µ–Ω–Ω—ã–µ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã
            result = subprocess.run(
                ['docker', 'ps', '--format', 'table {{.Names}}\t{{.Status}}'],
                capture_output=True,
                text=True
            )
            
            if result.returncode == 0:
                containers = result.stdout
                required_containers = [
                    'jonquils-postgres',
                    'jonquils-clickhouse', 
                    'jonquils-elasticsearch',
                    'jonquils-redis',
                    'jonquils-minio'
                ]
                
                running_containers = []
                for container in required_containers:
                    if container in containers and 'Up' in containers:
                        running_containers.append(container)
                
                self.test_result("Docker Containers", 
                               len(running_containers) == len(required_containers),
                               f"Running: {running_containers}")
            else:
                self.test_result("Docker Containers", False, "Docker not available")
                
        except Exception as e:
            self.test_result("Docker Containers", False, str(e))

    async def run_all_tests(self):
        """–ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö —Ç–µ—Å—Ç–æ–≤"""
        logger.info("üöÄ Starting Infrastructure Tests...")
        start_time = time.time()
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –≤—Å–µ —Ç–µ—Å—Ç—ã
        await self.test_postgresql()
        self.test_clickhouse()
        self.test_elasticsearch()
        self.test_redis()
        self.test_minio()
        await self.test_fastapi()
        self.test_docker_services()
        
        end_time = time.time()
        
        # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        logger.info("=" * 60)
        logger.info("üìä TEST RESULTS SUMMARY")
        logger.info("=" * 60)
        logger.info(f"Tests Run: {self.results['tests_run']}")
        logger.info(f"Tests Passed: {self.results['tests_passed']}")
        logger.info(f"Tests Failed: {self.results['tests_failed']}")
        logger.info(f"Success Rate: {(self.results['tests_passed']/self.results['tests_run']*100):.1f}%")
        logger.info(f"Execution Time: {end_time - start_time:.2f} seconds")
        
        if self.results['tests_failed'] > 0:
            logger.info("\n‚ùå FAILED TESTS:")
            for test_name, details in self.results['details'].items():
                if not details['passed']:
                    logger.info(f"  - {test_name}: {details['details']}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ —Ñ–∞–π–ª
        with open('test_results.json', 'w') as f:
            json.dump(self.results, f, indent=2)
        
        logger.info(f"\nüìÑ Detailed results saved to: test_results.json")
        
        return self.results['tests_failed'] == 0

async def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    tester = InfrastructureTest()
    success = await tester.run_all_tests()
    
    if success:
        logger.info("üéâ All tests passed! Infrastructure is ready.")
        sys.exit(0)
    else:
        logger.error("üí• Some tests failed. Please check the issues above.")
        sys.exit(1)

if __name__ == "__main__":
    asyncio.run(main())
